# -*- coding: utf-8 -*-
"""KR6 IK – TRAINING & EVALUATION PIPELINE A-4.2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18BkQi77KWEVThbVvdgljU--ShWZXFAsy

1) Robot tanımı (KR6 joint limitleri)
2) FK fonksiyonu (Torch, differentiable)
3) FK tabanlı sentetik dataset üretimi
4) Dataset & DataLoader
5) IK Neural Network
6) Constraint-aware Loss (A-3)
7) Training loop
8) Evaluation & metrikler
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

class KR6IKDataset(Dataset):
    def __init__(self, csv_path):
        df = pd.read_csv(csv_path)

        self.X = torch.tensor(
            df[["x", "y", "z", "qx", "qy", "qz", "qw"]].values,
            dtype=torch.float32
        )

        self.Y = torch.tensor(
            df[["theta1", "theta2", "theta3", "theta4", "theta5", "theta6"]].values,
            dtype=torch.float32
        )

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.Y[idx]

class KR6IKDataset(Dataset):
    def __init__(self, csv_path):
        df = pd.read_csv(csv_path)

        self.X = torch.tensor(
            df[["x", "y", "z", "qx", "qy", "qz", "qw"]].values,
            dtype=torch.float32
        )

        self.Y = torch.tensor(
            df[["t1", "t2", "t3", "t4", "t5", "t6"]].values, # Corrected column names
            dtype=torch.float32
        )

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.Y[idx]

dataset = KR6IKDataset("KR6_FK_Dataset.csv")

train_size = int(0.9 * len(dataset))
val_size   = len(dataset) - train_size

train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_set, batch_size=256, shuffle=True)
val_loader   = DataLoader(val_set, batch_size=256, shuffle=False)

class IKNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(7, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 6)
        )

    def forward(self, x):
        return self.net(x)

def forward_kinematics(theta):
    """
    theta: (B, 6)
    return: end-effector position (B, 3)
    """
    # Bu fonksiyon senin daha önce kullandığın FK fonksiyonu ile birebir olmalı
    x = torch.sum(torch.cos(theta), dim=1)
    y = torch.sum(torch.sin(theta), dim=1)
    z = torch.sum(theta, dim=1) * 0.1
    return torch.stack([x, y, z], dim=1)

JOINT_MIN = torch.tensor([-2.97, -2.09, -2.97, -3.14, -2.09, -6.28]).to(device)
JOINT_MAX = torch.tensor([ 2.97,  2.09,  2.97,  3.14,  2.09,  6.28]).to(device)

def joint_limit_penalty(theta):
    lower_violation = F.relu(JOINT_MIN - theta)
    upper_violation = F.relu(theta - JOINT_MAX)
    return torch.mean(lower_violation**2 + upper_violation**2)

def smoothness_penalty(theta):
    return torch.mean((theta[:, 1:] - theta[:, :-1])**2)

def total_loss(theta_pred, theta_gt, x_target):
    """
    theta_pred : (B, DOF)
    theta_gt   : (B, DOF)
    x_target   : (B, 7) - includes position (3) and quaternion (4)
    """

    # --- Forward Kinematics ---
    x_fk = forward_kinematics(theta_pred)

    # --- FK Position Error ---
    # x_target[:, :3] gets the position part (x, y, z)
    fk_error = torch.norm(x_fk - x_target[:, :3], dim=1)
    fk_loss = fk_error.mean()

    # --- Joint MSE (weak supervision) ---
    mse_loss = F.mse_loss(theta_pred, theta_gt)

    # --- Joint limit penalty ---
    jl_loss = joint_limit_penalty(theta_pred)

    # --- Smoothness loss ---
    smooth_loss = smoothness_penalty(theta_pred)

    # --- Weighted total ---
    total = (
        10.0 * fk_loss +
        0.1  * mse_loss +
        0.01 * jl_loss +
        0.05 * smooth_loss
    )

    return (
        total,
        fk_loss.detach(),
        mse_loss.detach(),
        jl_loss.detach(),
        smooth_loss.detach(),
        fk_error.detach()
    )

epochs = 100  # YES, faydalı

for epoch in range(epochs):
    model.train()

    total_loss_sum = 0
    fk_sum = 0
    fk_max = 0

    for X, Y in tqdm(train_loader):
        X = X.to(device)
        Y = Y.to(device)

        optimizer.zero_grad()

        theta_pred = model(X)

        loss, fk, mse, jl, smooth, fk_err = total_loss(theta_pred, Y, X)

        loss.backward()
        optimizer.step()

        total_loss_sum += loss.item()
        fk_sum += fk.mean().item()
        fk_max = max(fk_max, fk_err.max().item())

    print(
        f"[Epoch {epoch+1:03d}] "
        f"Total: {total_loss_sum/len(train_loader):.4f} | "
        f"FK(mean): {fk_sum/len(train_loader):.4f} m | "
        f"FK(max): {fk_max:.4f} m"
    )

model.eval()
fk_errors = []

with torch.no_grad():
    for X, Y in val_loader:
        X = X.to(device)
        Y = Y.to(device)

        theta_pred = model(X)
        ee_pred = forward_kinematics(theta_pred)
        ee_gt = X[:, :3]

        error = torch.norm(ee_pred - ee_gt, dim=1)
        fk_errors.append(error.cpu().numpy())

fk_errors = np.concatenate(fk_errors)
print("Mean FK Position Error (m):", fk_errors.mean())